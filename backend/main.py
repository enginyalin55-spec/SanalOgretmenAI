from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from google import genai
from google.genai import types
from supabase import create_client, Client
from dotenv import load_dotenv
import os
import json
import uuid
import re
from pydantic import BaseModel
from typing import Union, List, Dict, Any

# --- AYARLAR ---
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

SUPABASE_URL = os.getenv("SUPABASE_URL", "")
if SUPABASE_URL and not SUPABASE_URL.endswith("/"):
    SUPABASE_URL += "/"
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# --- Ä°STEMCÄ°LER ---
client = genai.Client(api_key=API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

MODELS_TO_TRY = ["gemini-2.0-flash-exp", "gemini-1.5-flash", "gemini-1.5-pro"]
WORD_COUNTS = {"A1": 75, "A2": 100, "B1": 125, "B2": 150, "C1": 175, "C2": 200}

# =======================================================
# ğŸ›¡ï¸ TDK KURALLARI (KOD Ä°Ã‡Ä°NE GÃ–MÃœLÃœ)
# =======================================================
def load_tdk_rules() -> List[Dict[str, Any]]:
    return [
        {
            "rule_id": "TDK_01_BAGLAC_DE",
            "title": "BaÄŸlaÃ§ Olan 'da/de'nin YazÄ±mÄ±",
            "text": "BaÄŸlaÃ§ olan 'da / de' her zaman ayrÄ± yazÄ±lÄ±r. CÃ¼mleden Ã§Ä±karÄ±lÄ±nca anlam bozulmaz.",
            "category": "BaÄŸlaÃ§lar"
        },
        {
            "rule_id": "TDK_02_BAGLAC_KI",
            "title": "BaÄŸlaÃ§ Olan 'ki'nin YazÄ±mÄ±",
            "text": "BaÄŸlaÃ§ olan 'ki' ayrÄ± yazÄ±lÄ±r. (Ä°stisnalar: sanki, oysaki, mademki, belki, halbuki, Ã§Ã¼nkÃ¼, meÄŸerki, illaki).",
            "category": "BaÄŸlaÃ§lar"
        },
        {
            "rule_id": "TDK_03_SORU_EKI",
            "title": "Soru Eki 'mÄ±/mi'nin YazÄ±mÄ±",
            "text": "Soru eki olan 'mÄ±, mi, mu, mÃ¼' her zaman ayrÄ± yazÄ±lÄ±r.",
            "category": "Ekler"
        },
        {
            "rule_id": "TDK_04_SEY_SOZ",
            "title": "'Åey' SÃ¶zcÃ¼ÄŸÃ¼nÃ¼n YazÄ±mÄ±",
            "text": "'Åey' sÃ¶zcÃ¼ÄŸÃ¼ her zaman ayrÄ± yazÄ±lÄ±r (her ÅŸey, bir ÅŸey, Ã§ok ÅŸey).",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_05_BUYUK_CUMLE",
            "title": "CÃ¼mle BaÅŸÄ± BÃ¼yÃ¼k Harf",
            "text": "CÃ¼mleler her zaman bÃ¼yÃ¼k harfle baÅŸlar.",
            "category": "BÃ¼yÃ¼k Harfler"
        },
        {
            "rule_id": "TDK_06_BUYUK_OZEL",
            "title": "Ã–zel Ä°simlerin YazÄ±mÄ±",
            "text": "KiÅŸi, Ã¼lke, ÅŸehir, dil ve millet adlarÄ± bÃ¼yÃ¼k harfle baÅŸlar (Ahmet, Ankara, TÃ¼rkÃ§e).",
            "category": "BÃ¼yÃ¼k Harfler"
        },
        {
            "rule_id": "TDK_07_BUYUK_KURUM",
            "title": "Kurum ve KuruluÅŸ AdlarÄ±",
            "text": "Kurum adlarÄ±nÄ±n her kelimesi bÃ¼yÃ¼k harfle baÅŸlar (TÃ¼rk Dil Kurumu).",
            "category": "BÃ¼yÃ¼k Harfler"
        },
        {
            "rule_id": "TDK_08_TARIH_GUN_AY",
            "title": "Belirli Tarihlerin YazÄ±mÄ±",
            "text": "Tam tarih bildiren ay ve gÃ¼n adlarÄ± bÃ¼yÃ¼k harfle baÅŸlar (29 MayÄ±s 1453 SalÄ±).",
            "category": "BÃ¼yÃ¼k Harfler"
        },
        {
            "rule_id": "TDK_09_KESME_OZEL",
            "title": "Ã–zel Ä°simlere Gelen Ekler",
            "text": "Ã–zel isimlere gelen Ã§ekim ekleri kesme iÅŸareti (') ile ayrÄ±lÄ±r (AyÅŸe'nin).",
            "category": "Noktalama"
        },
        {
            "rule_id": "TDK_10_KESME_KURUM",
            "title": "Kurum AdlarÄ±na Gelen Ekler",
            "text": "Kurum ve kuruluÅŸ adlarÄ±na gelen ekler kesmeyle ayrÄ±lmaz (BakanlÄ±ÄŸÄ±na).",
            "category": "Noktalama"
        },
        {
            "rule_id": "TDK_11_YARDIMCI_FIIL_SES",
            "title": "YardÄ±mcÄ± Fiillerde Ses OlayÄ±",
            "text": "Ses dÃ¼ÅŸmesi/tÃ¼remesi varsa bitiÅŸik (kaybolmak), yoksa ayrÄ± (terk etmek) yazÄ±lÄ±r.",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_12_SAYI_AYRI",
            "title": "SayÄ±larÄ±n YazÄ±mÄ±",
            "text": "Birden fazla kelimeden oluÅŸan sayÄ±lar ayrÄ± yazÄ±lÄ±r (on beÅŸ, yÃ¼z elli).",
            "category": "SayÄ±lar"
        },
        {
            "rule_id": "TDK_13_ULESTIRME",
            "title": "ÃœleÅŸtirme SayÄ±larÄ±",
            "text": "ÃœleÅŸtirme sayÄ±larÄ± rakamla deÄŸil yazÄ±yla yazÄ±lÄ±r (5'er deÄŸil beÅŸer).",
            "category": "SayÄ±lar"
        },
        {
            "rule_id": "TDK_14_KISALTMA_BUYUK",
            "title": "BÃ¼yÃ¼k Harfli KÄ±saltmalar",
            "text": "BÃ¼yÃ¼k harfli kÄ±saltmalara gelen ekler, son harfin okunuÅŸuna gÃ¶re gelir (TDK'dan deÄŸil TDK'den).",
            "category": "KÄ±saltmalar"
        },
        {
            "rule_id": "TDK_15_IKILEMELER",
            "title": "Ä°kilemelerin YazÄ±mÄ±",
            "text": "Ä°kilemeler ayrÄ± yazÄ±lÄ±r ve araya noktalama konmaz (yavaÅŸ yavaÅŸ).",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_16_PEKISTIRME",
            "title": "PekiÅŸtirmelerin YazÄ±mÄ±",
            "text": "PekiÅŸtirmeli sÄ±fatlar bitiÅŸik yazÄ±lÄ±r (masmavi, tertemiz).",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_17_YUMUSAK_G",
            "title": "YumuÅŸak G BaÅŸlangÄ±cÄ±",
            "text": "TÃ¼rkÃ§ede kelimeler 'ÄŸ' ile baÅŸlamaz.",
            "category": "YazÄ±m"
        },
        {
            "rule_id": "TDK_18_HER_BIR",
            "title": "'Her' Kelimesi",
            "text": "'Her' kelimesi genellikle ayrÄ± yazÄ±lÄ±r (her bir, her gÃ¼n). Ä°stisna: Herkes, herhangi.",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_19_BELIRSIZLIK_SIFATLARI",
            "title": "BitiÅŸik YazÄ±lan Belirsizlik Kelimeleri",
            "text": "Biraz, birÃ§ok, birkaÃ§, birtakÄ±m, herhangi kelimeleri bitiÅŸik yazÄ±lÄ±r.",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_20_NOKTA",
            "title": "CÃ¼mle Sonu Nokta",
            "text": "TamamlanmÄ±ÅŸ cÃ¼mlelerin sonuna nokta konur.",
            "category": "Noktalama"
        },
        {
            "rule_id": "TDK_21_VIRGUL",
            "title": "VirgÃ¼l KullanÄ±mÄ±",
            "text": "EÅŸ gÃ¶revli kelimeler ve sÄ±ralÄ± cÃ¼mleler arasÄ±na virgÃ¼l konur.",
            "category": "Noktalama"
        },
        {
            "rule_id": "TDK_22_DARALMA_KURALI",
            "title": "Gereksiz ÃœnlÃ¼ DaralmasÄ±",
            "text": "Yor eki dÄ±ÅŸÄ±nda, konuÅŸma dilindeki daralmalar yazÄ±ya geÃ§irilmez. (Yapcam -> YapacaÄŸÄ±m, Gelcem -> GeleceÄŸim).",
            "category": "YazÄ±m"
        },
        {
            "rule_id": "TDK_23_YANLIS_YALNIZ",
            "title": "YanlÄ±ÅŸ/YalnÄ±z YazÄ±mÄ±",
            "text": "DoÄŸrusu: YanlÄ±ÅŸ (yanÄ±lmaktan), YalnÄ±z (yalÄ±ndan).",
            "category": "YazÄ±m"
        },
        {
            "rule_id": "TDK_24_HERKES",
            "title": "Herkes YazÄ±mÄ±",
            "text": "'Herkes' kelimesi 's' ile biter, 'z' ile bitmez.",
            "category": "YazÄ±m"
        },
        {
            "rule_id": "TDK_25_SERTLESME",
            "title": "ÃœnsÃ¼z BenzeÅŸmesi (SertleÅŸme)",
            "text": "FÄ±stÄ±kÃ§Ä± Åahap Ã¼nsÃ¼zlerinden sonra 'c, d, g' -> 'Ã§, t, k' olur (kitapda deÄŸil kitapta, 1923'de deÄŸil 1923'te).",
            "category": "YazÄ±m"
        },
        {
            "rule_id": "TDK_26_HANE",
            "title": "Hane Kelimesi",
            "text": "Sesliyle bitenlerde 'ha' dÃ¼ÅŸer (hastane, postane). ÃœnsÃ¼zle bitenlerde kalÄ±r (dershane).",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_27_ART_ARDA",
            "title": "Art Arda YazÄ±mÄ±",
            "text": "'Art arda' ayrÄ± ve 't' ile yazÄ±lÄ±r (ardarda deÄŸil).",
            "category": "AyrÄ±/BitiÅŸik YazÄ±m"
        },
        {
            "rule_id": "TDK_28_YABANCI_KELIMELER",
            "title": "SÄ±k KarÄ±ÅŸtÄ±rÄ±lan Kelimeler",
            "text": "DoÄŸrular: ÅofÃ¶r, egzoz, metot, tÄ±raÅŸ, kÄ±lavuz, kulÃ¼p, sÃ¼rpriz.",
            "category": "YazÄ±m"
        },
        {
            "rule_id": "TDK_29_UNVANLAR",
            "title": "UnvanlarÄ±n YazÄ±mÄ±",
            "text": "KiÅŸi adlarÄ±yla kullanÄ±lan unvanlar bÃ¼yÃ¼k harfle baÅŸlar (AyÅŸe HanÄ±m, Doktor Ali).",
            "category": "BÃ¼yÃ¼k Harfler"
        },
        {
            "rule_id": "TDK_30_YONLER",
            "title": "YÃ¶n AdlarÄ±nÄ±n YazÄ±mÄ±",
            "text": "YÃ¶n adlarÄ± Ã¶zel isimden Ã¶nceyse bÃ¼yÃ¼k (DoÄŸu Anadolu), sonraysa kÃ¼Ã§Ã¼k (Anadolu'nun doÄŸusu) yazÄ±lÄ±r.",
            "category": "BÃ¼yÃ¼k Harfler"
        }
    ]

# --- METÄ°N TEMÄ°ZLÄ°ÄÄ° (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å) ---
_ZERO_WIDTH = re.compile(r"[\u200B\u200C\u200D\uFEFF]")

def normalize_text(text: str) -> str:
    """GÃ¶sterim ve genel temizlik iÃ§in (Orijinal hali korur)."""
    if not text: return ""
    text = text.replace("â€™", "'").replace("`", "'")
    text = _ZERO_WIDTH.sub("", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def normalize_match(text: str) -> str:
    """EÅŸleÅŸtirme iÃ§in (BÃ¼yÃ¼k/KÃ¼Ã§Ã¼k harf duyarsÄ±z)."""
    return normalize_text(text).casefold()

def validate_analysis(result: Dict[str, Any], full_text: str, allowed_rule_ids: set) -> Dict[str, Any]:
    if not isinstance(result, dict):
        return {"rubric": {}, "errors": [], "teacher_note": "Analiz formatÄ± hatalÄ±."}

    raw_errors = result.get("errors", [])
    if not isinstance(raw_errors, list): raw_errors = []

    clean_errors = []
    n = len(full_text)

    for err in raw_errors:
        if not isinstance(err, dict): continue

        rid = err.get("rule_id")
        if not rid or rid not in allowed_rule_ids: continue 

        span = err.get("span")
        if not isinstance(span, dict) or "start" not in span or "end" not in span:
            continue

        try:
            start, end = int(span["start"]), int(span["end"])
        except: continue

        if start < 0 or end <= start or end > n: continue

        wrong = err.get("wrong", "") or ""
        correct = err.get("correct", "") or ""
        evidence_fragment = full_text[start:end]

        # 0) Correct boÅŸsa: AI saÃ§malamasÄ± -> reddet
        if normalize_text(correct) == "":
            print(f"ğŸ—‘ï¸ DÃ¼zeltme boÅŸ, reddedildi: {wrong}")
            continue

        # 1) Gereksiz dÃ¼zeltme: wrong == correct (case/boÅŸluk farklarÄ± dahil) -> reddet
        # Bu satÄ±r "Ben -> Ben" hatasÄ±nÄ± Ã§Ã¶zer.
        if normalize_match(wrong) == normalize_match(correct):
            print(f"ğŸ—‘ï¸ Gereksiz dÃ¼zeltme (aynÄ± kelime), reddedildi: {wrong} -> {correct}")
            continue

        # 2) KanÄ±t uyuÅŸmasÄ±: span iÃ§indeki parÃ§a wrong ile eÅŸleÅŸmeli (case-insensitive)
        # Bu satÄ±r "gelcem" (kÃ¼Ã§Ã¼k) ile "Gelcem" (AI Ã§Ä±ktÄ±sÄ±) arasÄ±ndaki farkÄ± yok sayar ve hatayÄ± kabul eder.
        if normalize_match(evidence_fragment) != normalize_match(wrong):
            print(f"ğŸ—‘ï¸ KanÄ±t uyuÅŸmazlÄ±ÄŸÄ±: Model='{wrong}' Metin='{evidence_fragment}'")
            continue

        clean_errors.append({
            "wrong": wrong,
            "correct": correct,
            "type": err.get("type", "YazÄ±m"),
            "rule_id": rid,
            "explanation": err.get("explanation", ""),
            "span": {"start": start, "end": end}
        })

    clean_errors.sort(key=lambda x: (x["span"]["start"], -(x["span"]["end"] - x["span"]["start"])))
    final_errors = []
    last_end = -1

    for e in clean_errors:
        if e["span"]["start"] < last_end:
            continue
        final_errors.append(e)
        last_end = e["span"]["end"]

    result["errors"] = final_errors
    return result

# --- MODELLER ve CEFR ---
CEFR_KRITERLERI = {
    "A1": "Basit cÃ¼mleler, kendini tanÄ±tma. Kelime sÄ±rasÄ± hatalarÄ±nÄ± daha hoÅŸgÃ¶rÃ¼lÃ¼ deÄŸerlendir.",
    "A2": "Basit baÄŸlaÃ§larla cÃ¼mle baÄŸlayabilmeli; temel zamanlarÄ± ve en sÄ±k ekleri genelde doÄŸru kullanmalÄ±.",
    "B1": "BaÄŸlantÄ±lÄ± metin, neden-sonuÃ§, daha tutarlÄ± anlatÄ±m.",
    "B2": "Daha akÄ±cÄ±, daha doÄŸru yazÄ±m. SÄ±k yazÄ±m/noktalama hatalarÄ± daha fazla puan kÄ±rdÄ±rÄ±r.",
    "C1": "GeniÅŸ sÃ¶z varlÄ±ÄŸÄ±, neredeyse kusursuz yazÄ±m/dil bilgisi beklenir.",
}

class AnalyzeRequest(BaseModel):
    ocr_text: str
    image_url: str
    student_name: str
    student_surname: str
    classroom_code: str
    level: str
    country: str
    native_language: str

class UpdateScoreRequest(BaseModel):
    submission_id: Union[int, str]
    new_rubric: dict
    new_total: int

# --- ENDPOINTS ---
@app.get("/check-class/{code}")
async def check_class_code(code: str):
    try:
        response = supabase.table("classrooms").select("name").eq("code", code.upper().strip()).execute()
        if response.data: return {"valid": True, "class_name": response.data[0]["name"]}
        return {"valid": False}
    except: return {"valid": False}

@app.post("/ocr")
async def ocr_image(file: UploadFile = File(...), classroom_code: str = Form(...)):
    try:
        file_content = await file.read()
        file_ext = file.filename.split(".")[-1]
        unique_filename = f"{classroom_code}_{uuid.uuid4()}.{file_ext}"
        image_url = ""
        try:
            supabase.storage.from_("odevler").upload(unique_filename, file_content, {"content-type": file.content_type})
            res = supabase.storage.from_("odevler").get_public_url(unique_filename)
            image_url = res if isinstance(res, str) else res.get("publicUrl")
        except: pass

        extracted_text = ""
        prompt = "Bu resimdeki metni, el yazÄ±sÄ± olsa bile TÃ¼rkÃ§e olarak aynen metne dÃ¶k. Sadece metni ver."
        for model_name in MODELS_TO_TRY:
            try:
                response = client.models.generate_content(
                    model=model_name, contents=[prompt, types.Part.from_bytes(data=file_content, mime_type=file.content_type)]
                )
                extracted_text = (response.text or "").strip()
                if extracted_text: break
            except: continue
        
        if not extracted_text: return {"status": "error", "message": "OCR BaÅŸarÄ±sÄ±z"}
        return {"status": "success", "ocr_text": extracted_text, "image_url": image_url}
    except Exception as e: return {"status": "error", "message": str(e)}

@app.post("/analyze")
async def analyze_submission(data: AnalyzeRequest):
    print(f"ğŸ§  Analiz: {data.student_name} ({data.level})")

    # KODDAN OKUYORUZ
    all_rules = load_tdk_rules()
    allowed_ids = {r["rule_id"] for r in all_rules}
    
    rules_text = "\n".join([f"- ID: {r['rule_id']} | {r['title']}: {r['text']}" for r in all_rules])
    cefr_text = CEFR_KRITERLERI.get(data.level, "Genel deÄŸerlendirme.")

    prompt = f"""
    GÃ–REV: Ã–ÄŸrenci metnini analiz et.
    ZORUNLU TALÄ°MATLAR:
    1. SADECE aÅŸaÄŸÄ±daki "TDK KURALLARI" listesini kullan. Listede olmayan hatayÄ± YAZMA.
    2. Her hata iÃ§in MUTLAKA metindeki 'span' (start, end) bilgisini doÄŸru hesapla.
    3. 'wrong' alanÄ±, metindeki ilgili parÃ§a ile BÄ°REBÄ°R aynÄ± olmalÄ±.

    TDK KURALLARI:{rules_text}
    SEVÄ°YE ({data.level}): {cefr_text}
    METÄ°N: \"\"\"{data.ocr_text}\"\"\"

    JSON Ã‡IKTI FORMATI:
    {{
      "rubric": {{ "uzunluk": 0, "noktalama": 0, "dil_bilgisi": 0, "soz_dizimi": 0, "kelime": 0, "icerik": 0 }},
      "errors": [ {{ "wrong": "...", "correct": "...", "type": "...", "rule_id": "...", "explanation": "...", "span": {{ "start": 0, "end": 0 }} }} ],
      "teacher_note": "..."
    }}
    """
    
    analysis_result = None
    last_error = ""

    for model_name in MODELS_TO_TRY:
        try:
            response = client.models.generate_content(model=model_name, contents=prompt, config=types.GenerateContentConfig(response_mime_type="application/json"))
            text_resp = (response.text or "").strip().replace("```json", "").replace("```", "")
            raw_result = json.loads(text_resp)
            
            sanitized = validate_analysis(raw_result, data.ocr_text, allowed_ids)
            
            sanitized["score_total"] = sum(sanitized.get("rubric", {}).values())
            analysis_result = sanitized
            print(f"âœ… Analiz BaÅŸarÄ±lÄ±: {model_name}")
            break
        except Exception as e:
            last_error = str(e)
            continue

    if not analysis_result: raise HTTPException(status_code=500, detail=f"Hata: {last_error}")

    try:
        supabase.table("submissions").insert({
            "student_name": data.student_name, "student_surname": data.student_surname, "classroom_code": data.classroom_code,
            "image_url": data.image_url, "ocr_text": data.ocr_text, "level": data.level, "country": data.country,
            "native_language": data.native_language, "analysis_json": analysis_result, "score_total": analysis_result["score_total"]
        }).execute()
        return {"status": "success", "data": analysis_result}
    except Exception as e: return {"status": "success", "data": analysis_result, "warning": "DB HatasÄ±"}

@app.post("/student-history")
async def get_student_history(student_name: str = Form(...), student_surname: str = Form(...), classroom_code: str = Form(...)):
    try:
        response = supabase.table("submissions").select("*").eq("student_name", student_name).eq("student_surname", student_surname).eq("classroom_code", classroom_code).order("created_at", desc=True).execute()
        return {"status": "success", "data": response.data}
    except Exception as e: return {"status": "error", "message": str(e)}

@app.post("/update-score")
async def update_score(data: UpdateScoreRequest):
    try:
        supabase.table("submissions").update({"score_total": data.new_total, "analysis_json": data.new_rubric}).eq("id", data.submission_id).execute()
        return {"status": "success", "message": "Puan gÃ¼ncellendi"}
    except Exception as e: raise HTTPException(status_code=500, detail=str(e))